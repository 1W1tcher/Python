{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7015989,"sourceType":"datasetVersion","datasetId":4033896}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n\ndef load_idx_file(filename):\n    with open(filename, 'rb') as f:\n        # 读取文件头\n        magic_number = int.from_bytes(f.read(4), byteorder='big')\n        num_items = int.from_bytes(f.read(4), byteorder='big')\n\n        # 读取数据\n        if magic_number == 2051:  # 图像数据\n            num_rows = int.from_bytes(f.read(4), byteorder='big')\n            num_cols = int.from_bytes(f.read(4), byteorder='big')\n            data = np.frombuffer(f.read(), dtype=np.uint8)\n            data = data.reshape(num_items, num_rows, num_cols)\n        elif magic_number == 2049:  # 标签数据\n            data = np.frombuffer(f.read(), dtype=np.uint8)\n        else:\n            raise ValueError(\"Unknown magic number for IDX file.\")\n\n    return data\n\n# 指定本地MNIST数据集路径\nmnist_path = '/kaggle/input/mnist-data/MNIST_data'\n\n# 加载训练集和测试集\nx_train = load_idx_file(f'{mnist_path}/train-images-idx3-ubyte/train-images.idx3-ubyte')  \ny_train = load_idx_file(f'{mnist_path}/train-labels-idx1-ubyte/train-labels.idx1-ubyte')   \nx_test = load_idx_file(f'{mnist_path}/t10k-images-idx3-ubyte/t10k-images.idx3-ubyte')  \ny_test = load_idx_file(f'{mnist_path}/t10k-labels-idx1-ubyte/t10k-labels.idx1-ubyte') \n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T10:03:38.791769Z","iopub.execute_input":"2023-12-03T10:03:38.792165Z","iopub.status.idle":"2023-12-03T10:03:39.496278Z","shell.execute_reply.started":"2023-12-03T10:03:38.792127Z","shell.execute_reply":"2023-12-03T10:03:39.495355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 数据预处理\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# 将图像数据转换为张量，并进行标准化\nx_train_tensor = torch.Tensor(x_train).unsqueeze(1) / 255.0\ny_train_tensor = torch.Tensor(y_train).long()\nx_test_tensor = torch.Tensor(x_test).unsqueeze(1) / 255.0\ny_test_tensor = torch.Tensor(y_test).long()\n\n# 创建数据集和数据加载器\ntrain_dataset = TensorDataset(x_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n\nbatch_size = 64\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\n#搭建深度自编码器网络\nclass Autoencoder(nn.Module):\n    def __init__(self):\n        super(Autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(28 * 28, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, 16),\n            nn.ReLU(),\n            nn.Linear(16, 8),\n            nn.ReLU(),\n            nn.Linear(8, 2),  # bottleneck layer with 2 neurons\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(2, 8),\n            nn.ReLU(),\n            nn.Linear(8, 16),\n            nn.ReLU(),\n            nn.Linear(16, 32),\n            nn.ReLU(),\n            nn.Linear(32, 64),\n            nn.ReLU(),\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128, 28 * 28),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\n# 初始化模型、损失函数和优化器\nautoencoder = Autoencoder()\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n\n\n# 定义噪声因子\nnoise_factor = 0.4\n\n# 训练模型\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    for data, _ in train_loader:\n        # 在输入图像上添加高斯噪声\n        noisy_data = data + noise_factor * torch.randn(data.shape)\n\n        optimizer.zero_grad()\n        outputs = autoencoder(noisy_data)\n        loss = criterion(outputs, data.view(-1, 28 * 28))\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T10:03:48.855377Z","iopub.execute_input":"2023-12-03T10:03:48.855644Z","iopub.status.idle":"2023-12-03T10:11:21.825323Z","shell.execute_reply.started":"2023-12-03T10:03:48.855623Z","shell.execute_reply":"2023-12-03T10:11:21.824442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 评估模型\nautoencoder.eval()\n\n# 测试集的一个批次\nwith torch.no_grad():\n    test_data, _ = next(iter(test_loader))\n    # 在测试图像上添加高斯噪声\n    noisy_test_data = test_data + noise_factor * torch.randn(test_data.shape)\n    test_outputs = autoencoder(noisy_test_data)\n\n\n# 显示原始图像、噪声图像和降噪重建图像\nn = 10\nfig, axes = plt.subplots(3, n, figsize=(20, 6))\n\nfor i in range(n):\n    # 原始图像\n    axes[0, i].imshow(test_data[i].numpy().reshape(28, 28), cmap='gray')\n    axes[0, i].get_xaxis().set_visible(False)\n    axes[0, i].get_yaxis().set_visible(False)\n    axes[0, i].set_title('')\n\n    # 噪声图像\n    axes[1, i].imshow(noisy_test_data[i].numpy().reshape(28, 28), cmap='gray')\n    axes[1, i].get_xaxis().set_visible(False)\n    axes[1, i].get_yaxis().set_visible(False)\n    axes[1, i].set_title('')\n\n    # 降噪重建图像\n    axes[2, i].imshow(test_outputs[i].numpy().reshape(28, 28), cmap='gray')\n    axes[2, i].get_xaxis().set_visible(False)\n    axes[2, i].get_yaxis().set_visible(False)\n    axes[2, i].set_title('')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T10:13:11.496261Z","iopub.execute_input":"2023-12-03T10:13:11.496661Z","iopub.status.idle":"2023-12-03T10:13:12.283710Z","shell.execute_reply.started":"2023-12-03T10:13:11.496620Z","shell.execute_reply":"2023-12-03T10:13:12.283038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 数据预处理\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# 将图像数据转换为张量，并进行标准化\nx_train_tensor = torch.Tensor(x_train).unsqueeze(1) / 255.0\ny_train_tensor = torch.Tensor(y_train).long()\nx_test_tensor = torch.Tensor(x_test).unsqueeze(1) / 255.0\ny_test_tensor = torch.Tensor(y_test).long()\n\n# 创建数据集和数据加载器\ntrain_dataset = TensorDataset(x_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n\nbatch_size = 64\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\n#搭建深度自编码器网络\nclass Autoencoder(nn.Module):\n    def __init__(self):\n        super(Autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(28 * 28, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, 16),\n            nn.ReLU(),\n            nn.Linear(16, 8),\n            nn.ReLU(),\n            nn.Linear(8, 2),  # bottleneck layer with 2 neurons\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(2, 8),\n            nn.ReLU(),\n            nn.Linear(8, 16),\n            nn.ReLU(),\n            nn.Linear(16, 32),\n            nn.ReLU(),\n            nn.Linear(32, 64),\n            nn.ReLU(),\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128, 28 * 28),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\n# 初始化模型、损失函数和优化器\nautoencoder = Autoencoder()\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n\n# 训练模型\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    for data, _ in train_loader:\n        optimizer.zero_grad()\n        outputs = autoencoder(data)\n        loss = criterion(outputs, data.view(-1, 28 * 28))\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T09:39:03.706579Z","iopub.execute_input":"2023-12-03T09:39:03.707036Z","iopub.status.idle":"2023-12-03T09:39:59.715699Z","shell.execute_reply.started":"2023-12-03T09:39:03.707004Z","shell.execute_reply":"2023-12-03T09:39:59.714701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\n\n# 评估模型\nautoencoder.eval()\n\n# 获取测试集中的图像和标签\nwith torch.no_grad():\n    test_data, test_labels = next(iter(test_loader))\n    encoded_data = autoencoder.encoder(test_data.view(test_data.size(0), -1))\n\n# 对 Latent code 进行均匀采样\nnum_samples = 100\nlatent_samples = torch.rand((num_samples, 2))  # 2是 bottleneck layer 的维度\n\n# 利用解码器对采样结果进行恢复\nwith torch.no_grad():\n    decoded_samples = autoencoder.decoder(latent_samples)\n\n# 显示 Latent space 中的数字聚类情况\nplt.figure(figsize=(8, 6))\nplt.scatter(encoded_data[:, 0], encoded_data[:, 1], c=test_labels.numpy(), cmap='viridis')\nplt.title('Latent Space Visualization')\nplt.xlabel('Latent Dimension 1')\nplt.ylabel('Latent Dimension 2')\nplt.colorbar()\nplt.show()\n\n# 使用解码器将 Latent space 中的采样数字重构为图像\nplt.figure(figsize=(12, 4))\nfor i in range(num_samples):\n    plt.subplot(10, 10, i + 1)\n    plt.imshow(decoded_samples[i].view(28, 28).numpy(), cmap='gray')\n    plt.title(f'')\n    plt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T09:50:32.398824Z","iopub.execute_input":"2023-12-03T09:50:32.399145Z","iopub.status.idle":"2023-12-03T09:50:36.368480Z","shell.execute_reply.started":"2023-12-03T09:50:32.399124Z","shell.execute_reply":"2023-12-03T09:50:36.366868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# 定义深度自编码器模型\nclass Autoencoder(nn.Module):\n    def __init__(self):\n        super(Autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(28 * 28, 256),\n            nn.ReLU(),\n            nn.Linear(256, 64),\n            nn.ReLU(),\n            nn.Linear(64, 8),\n            nn.ReLU(),\n            nn.Linear(8, 2),  # bottleneck layer with 2 neurons\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(2, 8),\n            nn.ReLU(),\n            nn.Linear(8, 64),\n            nn.ReLU(),\n            nn.Linear(64, 256),\n            nn.ReLU(),\n            nn.Linear(256, 28 * 28),\n            nn.Sigmoid()  # 输出范围在 [0, 1]\n        )\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\n# 初始化模型、损失函数和优化器（添加权重衰减项）\nautoencoder = Autoencoder()\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=0.001, weight_decay=1e-5)  # 添加权重衰减项\n\n# 训练模型\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    for data, _ in train_loader:\n        optimizer.zero_grad()\n        outputs = autoencoder(data)\n        loss = criterion(outputs, data.view(-1, 28 * 28))\n        \n        # 添加 L2 正则化项\n        l2_regularization = sum(torch.sum(param**2) for param in autoencoder.parameters())\n        loss += 1e-5 * l2_regularization\n        \n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2023-12-03T09:54:06.557242Z","iopub.execute_input":"2023-12-03T09:54:06.558438Z","iopub.status.idle":"2023-12-03T09:55:23.340072Z","shell.execute_reply.started":"2023-12-03T09:54:06.558404Z","shell.execute_reply":"2023-12-03T09:55:23.338828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\n\n# 评估模型\nautoencoder.eval()\n\n# 获取测试集中的图像和标签\nwith torch.no_grad():\n    test_data, test_labels = next(iter(test_loader))\n    encoded_data = autoencoder.encoder(test_data.view(test_data.size(0), -1))\n\n# 对 Latent code 进行均匀采样\nnum_samples = 100\nlatent_samples = torch.rand((num_samples, 2))  # 2是 bottleneck layer 的维度\n\n# 利用解码器对采样结果进行恢复\nwith torch.no_grad():\n    decoded_samples = autoencoder.decoder(latent_samples)\n\n# 显示 Latent space 中的数字聚类情况\nplt.figure(figsize=(8, 6))\nplt.scatter(encoded_data[:, 0], encoded_data[:, 1], c=test_labels.numpy(), cmap='viridis')\nplt.title('Latent Space Visualization')\nplt.xlabel('Latent Dimension 1')\nplt.ylabel('Latent Dimension 2')\nplt.colorbar()\nplt.show()\n\n# 使用解码器将 Latent space 中的采样数字重构为图像\nplt.figure(figsize=(12, 4))\nfor i in range(num_samples):\n    plt.subplot(10, 10, i + 1)\n    plt.imshow(decoded_samples[i].view(28, 28).numpy(), cmap='gray')\n    plt.title(f'')\n    plt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T09:55:27.551146Z","iopub.execute_input":"2023-12-03T09:55:27.551587Z","iopub.status.idle":"2023-12-03T09:55:30.601236Z","shell.execute_reply.started":"2023-12-03T09:55:27.551556Z","shell.execute_reply":"2023-12-03T09:55:30.599932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}