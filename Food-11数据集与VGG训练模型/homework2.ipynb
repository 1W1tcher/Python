{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":21471.99308,"end_time":"2023-11-05T12:34:36.631618","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-11-05T06:36:44.638538","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 文件夹路径\nfolder_path = ['/kaggle/input/food11/food-11/training',\n               '/kaggle/input/food11/food-11/validation',\n               '/kaggle/input/food11/food-11/testing']\n\ntrain_foods = []  # 整形\ntrain_images = []  # numpy.ndarray类型\nvalid_foods = []\nvalid_images = []\ntest_images = []\ntest_pic_names = []\n\nclass_names = ['Bread', \n               'Dairy product', \n               'Dessert', \n               'Egg',\n               'Fried food', \n               'Meat', \n               'Noodles/Pasta', \n               'Rice', \n               'Seafood', \n               'Soup', \n               'Vegetables/Fruits']\nclass_names_cn = ['面包', \n                  '乳制品', \n                  '甜点',\n                  '鸡蛋', \n                  '油炸食品',\n                  '肉类', \n                  '面条/意大利面',\n                  '米饭', \n                  '海鲜', \n                  '汤', \n                  '蔬菜/水果']\n\n# 遍历文件夹中所有文件\nfor i in range(2):\n    for file_name in os.listdir(folder_path[i]):\n        file_path = folder_path[i] + '/' + file_name\n        if i==1:\n            # 验证集\n            valid_foods.append(int(file_name.split('_')[0]))\n            valid_images.append(cv2.imread(file_path))\n        # 训练集\n        train_foods.append(int(file_name.split('_')[0]))\n        train_images.append(cv2.imread(file_path))\n\nfor file_name in os.listdir(folder_path[2]):\n    test_pic_names.append(('/food11/testing/'+file_name))\n    file_path = folder_path[2] + '/' + file_name\n    test_images.append(cv2.imread(file_path))","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":194.782275,"end_time":"2023-11-05T06:40:02.847502","exception":false,"start_time":"2023-11-05T06:36:48.065227","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:02.494696Z","iopub.execute_input":"2023-11-07T06:55:02.495610Z","iopub.status.idle":"2023-11-07T06:55:23.643893Z","shell.execute_reply.started":"2023-11-07T06:55:02.495574Z","shell.execute_reply":"2023-11-07T06:55:23.640370Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;66;03m# 训练集\u001b[39;00m\n\u001b[1;32m     51\u001b[0m         train_foods\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(file_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m---> 52\u001b[0m         train_images\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path[\u001b[38;5;241m2\u001b[39m]):\n\u001b[1;32m     55\u001b[0m     test_pic_names\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/food11/testing/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mfile_name))\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import torchvision.transforms as transforms\nplt.imshow(train_images[0][:,:,::-1])\n# [:,:,::-1]用于反转img数组的颜色通道，以便正确显示图像\n# opencv 是BGR, matplotlib是RGB\nplt.savefig('/kaggle/working/1.png', bbox_inches='tight', dpi=800)\nplt.show()\nprint(train_images[0].shape)","metadata":{"papermill":{"duration":5.519329,"end_time":"2023-11-05T06:40:08.376157","exception":false,"start_time":"2023-11-05T06:40:02.856828","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.644565Z","iopub.status.idle":"2023-11-07T06:55:23.644890Z","shell.execute_reply.started":"2023-11-07T06:55:23.644726Z","shell.execute_reply":"2023-11-07T06:55:23.644741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\n#图像增强\n# pytorch是NCHW\ntrain_transform = transforms.Compose([\n    transforms.ToPILImage(), # 转化为PIL类型便于进行Resize\n    transforms.Resize((128, 128)),\n    transforms.ColorJitter(brightness=0.5, contrast=0.5),#随机调整亮度和对比度\n    transforms.RandomHorizontalFlip(),#随机将图片水平翻转\n    transforms.RandomRotation(15),#随机旋转图片\n    transforms.ToTensor(),#将图片转化为Tensor(GBR->NCHW)\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) #归一化到-1dao1\n])\n\n#测试集图像处理\nvalid_transform = transforms.Compose([\n    transforms.ToPILImage(), # 转化为PIL类型便于进行Resize    \n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) #归一化到-1 1\n    \n])","metadata":{"papermill":{"duration":0.023114,"end_time":"2023-11-05T06:40:08.412440","exception":false,"start_time":"2023-11-05T06:40:08.389326","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.647358Z","iopub.status.idle":"2023-11-07T06:55:23.647752Z","shell.execute_reply.started":"2023-11-07T06:55:23.647570Z","shell.execute_reply":"2023-11-07T06:55:23.647593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n# a为随机从train_images中取出的4个值\ntest_a = random.sample(train_images, 4)\n\nmean = [0.5, 0.5, 0.5]\nstd = [0.5, 0.5, 0.5]\n\n# 创建一个4x2的子图，并在每个子图中显示一张图片\nfig, axes = plt.subplots(nrows=4, ncols=2, figsize=(8, 16))\nfor i, ax in enumerate(axes.flat):\n    if (i % 2==0) or (i == 0):\n        a = test_a[i//2]\n    else:\n        a = train_transform(test_a[i//2])\n        # 反标准化\n        a = a * torch.tensor(std).view(3, 1, 1) + torch.tensor(mean).view(3, 1, 1)\n        # Tensor转换为Numpy\n        a = a.numpy()\n        # CHW->HWC\n        a = np.transpose(a, (1, 2, 0))\n    a = a[:, :, ::-1] # 将每个通道的值逆序排列 BGR to RGB\n    \n    # 显示图片\n    ax.imshow(a)\n    ax.axis('off')\nplt.savefig('/kaggle/working/2.png', bbox_inches='tight', dpi=800)\nplt.show()","metadata":{"papermill":{"duration":7.174293,"end_time":"2023-11-05T06:40:15.599118","exception":false,"start_time":"2023-11-05T06:40:08.424825","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.648859Z","iopub.status.idle":"2023-11-07T06:55:23.649183Z","shell.execute_reply.started":"2023-11-07T06:55:23.649021Z","shell.execute_reply":"2023-11-07T06:55:23.649036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass MyDataset(Dataset):\n    def __init__(self, features, labels=None, transform=None):\n        self.features = features\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, index):\n        feature = self.features[index]\n        if self.labels:\n            label = self.labels[index]\n        else:\n            label = None\n        # 应用转换操作\n        if self.transform:\n            feature = self.transform(feature)\n        return feature, label","metadata":{"papermill":{"duration":0.037927,"end_time":"2023-11-05T06:40:15.665044","exception":false,"start_time":"2023-11-05T06:40:15.627117","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.651072Z","iopub.status.idle":"2023-11-07T06:55:23.651424Z","shell.execute_reply.started":"2023-11-07T06:55:23.651246Z","shell.execute_reply":"2023-11-07T06:55:23.651261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_data = MyDataset(features = train_images,\n                       labels = train_foods,\n                       transform = train_transform)\nvalid_data = MyDataset(features = valid_images,\n                       labels = valid_foods,\n                       transform = valid_transform)\ntrain_set = DataLoader(dataset = train_data,\n                       batch_size = 8,\n                       shuffle = True,\n                       drop_last = True)\nvalid_set = DataLoader(dataset = valid_data,\n                      batch_size = 8,\n                      shuffle = True,\n                      drop_last = True)","metadata":{"papermill":{"duration":0.035912,"end_time":"2023-11-05T06:40:15.729289","exception":false,"start_time":"2023-11-05T06:40:15.693377","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.652587Z","iopub.status.idle":"2023-11-07T06:55:23.652924Z","shell.execute_reply.started":"2023-11-07T06:55:23.652745Z","shell.execute_reply":"2023-11-07T06:55:23.652759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set = MyDataset(features = test_images, transform=valid_transform)","metadata":{"papermill":{"duration":0.034031,"end_time":"2023-11-05T06:40:15.790378","exception":false,"start_time":"2023-11-05T06:40:15.756347","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.654610Z","iopub.status.idle":"2023-11-07T06:55:23.655102Z","shell.execute_reply.started":"2023-11-07T06:55:23.654837Z","shell.execute_reply":"2023-11-07T06:55:23.654861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ndvc = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(dvc)","metadata":{"papermill":{"duration":0.106121,"end_time":"2023-11-05T06:40:15.923739","exception":false,"start_time":"2023-11-05T06:40:15.817618","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.656773Z","iopub.status.idle":"2023-11-07T06:55:23.657116Z","shell.execute_reply.started":"2023-11-07T06:55:23.656945Z","shell.execute_reply":"2023-11-07T06:55:23.656962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"papermill":{"duration":13.223988,"end_time":"2023-11-05T06:40:29.175399","exception":false,"start_time":"2023-11-05T06:40:15.951411","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.658359Z","iopub.status.idle":"2023-11-07T06:55:23.658718Z","shell.execute_reply.started":"2023-11-07T06:55:23.658555Z","shell.execute_reply":"2023-11-07T06:55:23.658571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchsummary import summary\n\n# 定义残差块\nclass Residual(nn.Module):\n    def __init__(self, input_channels, out_channels, use_1x1conv = False, strides = 1):\n        super().__init__()\n        self.conv1 = nn.Conv2d(input_channels, out_channels, kernel_size = 3, padding = 1, stride = strides)\n        # x-3+2/s +1 = x  s=2,减半\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding = 1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        if use_1x1conv: #1x1卷积改变x维度，使得其与卷积后的y维度一致，可以相加\n            self.conv3 = nn.Conv2d(input_channels, out_channels, kernel_size = 1, stride = strides)\n        else:\n            self.conv3 = None\n    def forward(self, x):\n        y = F.relu(self.bn1(self.conv1(x)))\n        y = self.bn2(self.conv2(y))\n        if self.conv3:\n            x = self.conv3(x) #改变维度\n        y += x\n        return F.relu(y)\n\n# 生成残差块\ndef resnet_block(input_channels, out_channels, num_residuals,\n                 half_wh=False):\n    blk = []\n    for i in range(num_residuals):\n        # half_wh就高宽减半(strides=2)，否则不变\n        if i == 0 and not half_wh:\n            blk.append(Residual(input_channels, out_channels,\n                                use_1x1conv=True, strides=1))\n        elif i == 0 and half_wh:\n            blk.append(Residual(input_channels, out_channels,\n                                use_1x1conv=True, strides=2))\n        else: \n            blk.append(Residual(out_channels, out_channels))\n    return blk\n\n\n\nclass qyeNet(nn.Module):\n    def __init__(self):\n        super(qyeNet, self).__init__()\n        self.conv_pool1 = nn.Sequential(\n            # 输入 224*224*3\n            *resnet_block(3, 64, 1),\n            # 输出224 224 64\n            nn.MaxPool2d(kernel_size=2, stride=2)\n            # 输出(224-2)/2 +1 = 112 112 64\n        )\n        self.conv_pool2 = nn.Sequential(\n            # 输入 112 112 64\n            *resnet_block(64, 128, 1),\n            # 输出 112 112 128\n            nn.MaxPool2d(kernel_size=2, stride=2)\n            # 输出 56 56 128\n        )\n        self.conv_pool3 = nn.Sequential(\n            *resnet_block(128, 256, 2),\n            # 输出 56\n            nn.MaxPool2d(kernel_size=2, stride=2)\n            # 输出 28 28 256\n        )\n        self.conv_pool4 = nn.Sequential(\n            *resnet_block(256, 512, 2),\n            # 输出28 28 512\n            nn.MaxPool2d(kernel_size=2, stride=2)\n            # 输出14 14 512\n        )\n        self.conv_pool5 = nn.Sequential(\n            *resnet_block(512, 512, 2),\n            # 输出 14 14 512\n            nn.MaxPool2d(kernel_size=2, stride=2)\n            # 输出 7 7 512\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(7*7*512, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, 11)\n            # 使用交叉熵误差函数，最后一层不用softmax\n        )\n    def forward(self, x):\n        x = self.conv_pool1(x)\n        x = self.conv_pool2(x)\n        x = self.conv_pool3(x)\n        x = self.conv_pool4(x)\n        x = self.conv_pool5(x)\n        x = x.view(-1, 7*7*512)\n        x = self.fc(x)\n        return x\n\nmodel_qye = qyeNet().to(dvc)\nsummary(model_qye, (3, 224, 224))","metadata":{"papermill":{"duration":8.929635,"end_time":"2023-11-05T06:40:38.133819","exception":false,"start_time":"2023-11-05T06:40:29.204184","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.660595Z","iopub.status.idle":"2023-11-07T06:55:23.661076Z","shell.execute_reply.started":"2023-11-07T06:55:23.660820Z","shell.execute_reply":"2023-11-07T06:55:23.660842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid(model, valid_set):\n    model.eval()\n    valid_correct = 0\n    for i, data in enumerate(valid_set, 0):\n        data_len = len(data[0])\n        features, labels = data\n        features, labels = features.to(dvc), labels.to(dvc)\n        preds = model(features)\n        _, ans = torch.max(preds, 1) # 返回1维度上的最大值的索引，_是最大值\n        valid_correct += torch.sum(ans==labels.data)\n    valid_accuracy = 100*valid_correct/(len(valid_set)*data_len)\n    print(f'Accuracy on valid set:{valid_accuracy:.3f}%')\n    return valid_accuracy","metadata":{"papermill":{"duration":0.036827,"end_time":"2023-11-05T06:40:38.198512","exception":false,"start_time":"2023-11-05T06:40:38.161685","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.662353Z","iopub.status.idle":"2023-11-07T06:55:23.662844Z","shell.execute_reply.started":"2023-11-07T06:55:23.662594Z","shell.execute_reply":"2023-11-07T06:55:23.662617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\nimport time, math\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, StepLR\n\nSHA_TZ = timezone(\n    timedelta(hours=8),\n    name='Asia/Shanghai',\n)\n\ndef get_cos(t):\n    return 0.0051 + 0.0049*math.cos(2*math.pi*t/10)\n\ndef train_valid(model, train_set, valid_set):\n    writer = SummaryWriter('/kaggle/working/runs/vgg') # 开始记录\n    loss_func = nn.CrossEntropyLoss() #交叉熵损失\n#     optimizer = torch.optim.SGD(model.parameters(), lr=0.01) #优化器以及学习率\n    epochs = 100\n    start_time = time.time()\n    good_num = 0 # 学习率大于85%的次数或模型过拟合的次数\n    for epoch in range(epochs):\n        lr = get_cos(epoch)\n        print(lr)\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr) #优化器以及学习率\n        if good_num >= 5:\n            print(f'run {epoch} epoch')\n            break\n        model.train()\n        sum_loss = 0\n        train_correct = 0\n        time_now = datetime.utcnow().astimezone(SHA_TZ)\n        print(f'[{epoch+1}/{epochs}]  time now: {time_now.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n        for i, data in enumerate(train_set, 0):\n            features, labels = data\n            data_len = len(data[0])\n            features, labels = features.to(dvc), labels.to(dvc)\n            preds = model(features)\n            model.zero_grad() #梯度清零\n            # 计算损失\n            loss = loss_func(preds, labels)\n            loss.backward() # 反向传播\n            optimizer.step()\n#             scheduler.step()\n            sum_loss += loss.data\n            _, ans = torch.max(preds, 1) # 此时preds第0维度有5个数据，ans也是5*1的张量\n            train_correct += torch.sum(ans==labels.data) # ans5*1 ，这里输出的是5个里面预测准确的数量\n        train_ac = 100*train_correct/(len(train_set)*data_len) # 训练集准确率\n        train_loss = sum_loss/(len(train_set)*data_len) # 训练集损失\n        print(f'Loss on train set: {train_loss:.3f} Accuracy on train set: {train_ac:.3f}%')\n        valid_ac = valid(model, valid_set) # 测试集准确率(有输出)\n        if valid_ac > 90 or train_ac > 99:\n            good_num += 1\n        elif valid_ac == 95:\n            good_num = 5\n        writer.add_scalar(\"Accuracy/train\", train_ac, epoch)\n        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n        writer.add_scalar(\"Accuracy/valid\", valid_ac, epoch)\n    end_time = time.time()\n    print(f'cost time {end_time - start_time}')\n    writer.close() # 结束记录","metadata":{"papermill":{"duration":7.929332,"end_time":"2023-11-05T06:40:46.155177","exception":false,"start_time":"2023-11-05T06:40:38.225845","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.664625Z","iopub.status.idle":"2023-11-07T06:55:23.665097Z","shell.execute_reply.started":"2023-11-07T06:55:23.664847Z","shell.execute_reply":"2023-11-07T06:55:23.664869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_valid(model_qye, train_set, valid_set)","metadata":{"papermill":{"duration":18780.455918,"end_time":"2023-11-05T11:53:46.639411","exception":false,"start_time":"2023-11-05T06:40:46.183493","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.666865Z","iopub.status.idle":"2023-11-07T06:55:23.667225Z","shell.execute_reply.started":"2023-11-07T06:55:23.667049Z","shell.execute_reply":"2023-11-07T06:55:23.667067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model_qye, '/kaggle/working/qyecos.pth')","metadata":{"papermill":{"duration":0.946007,"end_time":"2023-11-05T11:53:47.626081","exception":false,"start_time":"2023-11-05T11:53:46.680074","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.668921Z","iopub.status.idle":"2023-11-07T06:55:23.669273Z","shell.execute_reply.started":"2023-11-07T06:55:23.669100Z","shell.execute_reply":"2023-11-07T06:55:23.669117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef predict(model, data_set, length, prt_info=True):\n    model.eval()\n    model.cpu()\n    '''\n    data：DataLoader类型\n    length: 预测数据批量\n    prt_info: 是否打印预测细节\n    '''\n    data_iter = iter(data_set) # 定义迭代器去迭代数据\n    pre_correct = 0\n    true_labels = [] # 真实标签集合\n    pred_labels = [] # 预测标签集合\n    pred_ans = [] #1代表正确，0错误\n    for i in range(length):\n        try: # 防止迭代溢出\n            data = next(data_iter)\n        except StopIteration:\n            break #长度超了就跳出循环\n        feature, label = data\n        # 预测并打印预测标签\n        feature = feature.cpu()\n        if label != None:\n            label = label.cpu()\n            data_len = len(data[0])\n        else:\n            feature = feature.reshape((1, 3, 224, 224))\n            data_len = 1\n        pre_tensor = model(feature)\n        _, pre_label = torch.max(pre_tensor, 1)\n        if label != None:\n            pre_correct += torch.sum(pre_label==label) # 5*1\n        if prt_info:\n            # 为可视化准备\n            fig, ax = plt.subplots(1, data_len, figsize=(15, 3))  # 创建1行x列的子图网格\n        for j in range(data_len):\n            if prt_info: #要输出信息时\n            # 可视化图片\n            # 将通道维度调整到最后一个维度\n            \n                f_np = feature[j].cpu() * torch.tensor(std).view(3, 1, 1) + torch.tensor(mean).view(3, 1, 1)\n                f_np = f_np.numpy()\n                f_np = np.transpose(f_np, (1, 2, 0))\n                f_np = f_np[:, :, ::-1]\n                \n                if data_len != 1:\n                    # 展示图像\n                    ax[j].imshow(f_np)\n                    ax[j].axis('off')\n                else:\n                    ax.imshow(f_np)\n                    ax.axis('off')\n            \n                # 打印正确的标签\n                if label != None:\n                    print(\"Correct label: \", class_names[label[j]])\n                print('Predict label: ', class_names[pre_label[j]])\n                print('-----------------------------------\\n\\n')\n                                \n            # 将预测数据与真实数据加入各自集合中\n            if label !=None:\n                true_labels.append(label[j].item())\n                pred_ans.append(1 if pre_label[j].item()==label[j].item() else 0)\n            pred_labels.append(pre_label[j].item())\n            \n        plt.show()\n    # 计算正确率\n    if label!=None:\n        correct = (100*pre_correct/(length*data_len))\n        if prt_info: # 要输出信息时\n            print('\\n\\ncorrect: %.3f%%' % correct)\n    return pred_labels, true_labels, pred_ans","metadata":{"papermill":{"duration":0.058249,"end_time":"2023-11-05T11:53:47.725839","exception":false,"start_time":"2023-11-05T11:53:47.667590","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.670446Z","iopub.status.idle":"2023-11-07T06:55:23.670775Z","shell.execute_reply.started":"2023-11-07T06:55:23.670620Z","shell.execute_reply":"2023-11-07T06:55:23.670635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(model_qye, test_set, 5)","metadata":{"papermill":{"duration":2.936393,"end_time":"2023-11-05T11:53:50.702428","exception":false,"start_time":"2023-11-05T11:53:47.766035","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.672412Z","iopub.status.idle":"2023-11-07T06:55:23.672787Z","shell.execute_reply.started":"2023-11-07T06:55:23.672612Z","shell.execute_reply":"2023-11-07T06:55:23.672630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(model_qye, valid_set, 5)","metadata":{"papermill":{"duration":12.516996,"end_time":"2023-11-05T11:54:03.285822","exception":false,"start_time":"2023-11-05T11:53:50.768826","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.673863Z","iopub.status.idle":"2023-11-07T06:55:23.674238Z","shell.execute_reply.started":"2023-11-07T06:55:23.674043Z","shell.execute_reply":"2023-11-07T06:55:23.674060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\ndef save_predict_csv(model, data_set, length, name_row, write_path, file_names=None):\n    preds, labels, pred_ans = predict(model, data_set, length, False)\n    if file_names != None:\n        ans = np.array([preds, file_names[0:length]]).T\n    else:\n        ans = np.array([preds, labels, pred_ans]).T\n    with open(write_path, mode='w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(name_row)\n        i = 0\n        for row in ans:\n            writer.writerow(row)\n            i+=1\n        print(f'Write over {i} lines in file {write_path}')","metadata":{"papermill":{"duration":0.081,"end_time":"2023-11-05T11:54:03.440583","exception":false,"start_time":"2023-11-05T11:54:03.359583","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.675610Z","iopub.status.idle":"2023-11-07T06:55:23.675959Z","shell.execute_reply.started":"2023-11-07T06:55:23.675785Z","shell.execute_reply":"2023-11-07T06:55:23.675802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_predict_csv(model_qye, test_set, len(test_set), ['pred', 'filename'], '/kaggle/working/ans_ours.csv', test_pic_names)","metadata":{"papermill":{"duration":713.7131,"end_time":"2023-11-05T12:05:57.221780","exception":false,"start_time":"2023-11-05T11:54:03.508680","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.677225Z","iopub.status.idle":"2023-11-07T06:55:23.677700Z","shell.execute_reply.started":"2023-11-07T06:55:23.677457Z","shell.execute_reply":"2023-11-07T06:55:23.677480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_predict_csv(model_qye, valid_set, len(valid_set), ['pred', 'true', 'ans'], '/kaggle/working/valid_ours.csv')","metadata":{"papermill":{"duration":773.712981,"end_time":"2023-11-05T12:18:51.004639","exception":false,"start_time":"2023-11-05T12:05:57.291658","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.679227Z","iopub.status.idle":"2023-11-07T06:55:23.679585Z","shell.execute_reply.started":"2023-11-07T06:55:23.679410Z","shell.execute_reply":"2023-11-07T06:55:23.679430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\ndef draw_confusion_matrix(label_true, label_pred, label_name, title=\"Confusion Matrix\", pdf_save_path=None, dpi=100):\n    cm = confusion_matrix(y_true=label_true, y_pred=label_pred, normalize='true')\n\n    fig = plt.figure(figsize=(8, 8))  # 设置图像大小\n    plt.imshow(cm, cmap='Blues')\n    plt.title(title)\n    plt.xlabel(\"Predict label\")\n    plt.ylabel(\"Truth label\")\n    plt.yticks(range(len(label_name)), label_name)\n    plt.xticks(range(len(label_name)), label_name, rotation=90)\n\n    plt.tight_layout()\n\n    plt.colorbar()\n\n    for i in range(len(label_name)):\n        for j in range(len(label_name)):\n            color = (1, 1, 1) if i == j else (0, 0, 0)  \n            value = float(format('%.2f' % cm[j, i]))\n            plt.text(i, j, value, verticalalignment='center', horizontalalignment='center', color=color)\n\n    if pdf_save_path is not None:\n        plt.savefig(pdf_save_path, bbox_inches='tight', dpi=dpi)\n\n    plt.show()  # 显示图像","metadata":{"papermill":{"duration":0.902713,"end_time":"2023-11-05T12:18:51.977145","exception":false,"start_time":"2023-11-05T12:18:51.074432","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.680367Z","iopub.status.idle":"2023-11-07T06:55:23.680718Z","shell.execute_reply.started":"2023-11-07T06:55:23.680555Z","shell.execute_reply":"2023-11-07T06:55:23.680571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv('/kaggle/working/valid_ours.csv')\npred_lst = data['pred']\ntrue_lst = data['true']\nans_lst = data['ans']","metadata":{"papermill":{"duration":0.093176,"end_time":"2023-11-05T12:18:52.141509","exception":false,"start_time":"2023-11-05T12:18:52.048333","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.681981Z","iopub.status.idle":"2023-11-07T06:55:23.682332Z","shell.execute_reply.started":"2023-11-07T06:55:23.682161Z","shell.execute_reply":"2023-11-07T06:55:23.682178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 训练集混淆矩阵\ndraw_confusion_matrix(label_true=true_lst,\n                      label_pred=pred_lst,\n                      label_name=class_names,\n                      title='Validation Dataset Confusion Matrix',\n                      pdf_save_path='/kaggle/working/valid.png',\n                      dpi=1000\n                     )","metadata":{"papermill":{"duration":7.281537,"end_time":"2023-11-05T12:18:59.494085","exception":false,"start_time":"2023-11-05T12:18:52.212548","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.683965Z","iopub.status.idle":"2023-11-07T06:55:23.684317Z","shell.execute_reply.started":"2023-11-07T06:55:23.684146Z","shell.execute_reply":"2023-11-07T06:55:23.684162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuarcy = 100*(sum(ans_lst)*1.0/len(ans_lst))\nprint(f'Eval accuarcy: {accuarcy:.3f} %')","metadata":{"papermill":{"duration":0.083052,"end_time":"2023-11-05T12:18:59.655827","exception":false,"start_time":"2023-11-05T12:18:59.572775","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.685665Z","iopub.status.idle":"2023-11-07T06:55:23.686045Z","shell.execute_reply.started":"2023-11-07T06:55:23.685859Z","shell.execute_reply":"2023-11-07T06:55:23.685876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 搭建vgg19_bn模型并打印模型参数","metadata":{"papermill":{"duration":0.073508,"end_time":"2023-11-05T12:18:59.802102","exception":false,"start_time":"2023-11-05T12:18:59.728594","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n# from torchsummary import summary\n\nclass my_VGG19(nn.Module):\n    def __init__(self):\n        super(my_VGG19, self).__init__()\n        self.conv_pool1 = nn.Sequential(\n            # 输入 224*224*3\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            # 输出 [(224-3+2)/1]+1 = 224\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            # 输出224 224 64\n            nn.MaxPool2d(kernel_size=2, stride=2)\n            # 输出(224-2)/2 +1 = 112 112 64\n        )\n        self.conv_pool2 = nn.Sequential(\n            # 输入 112 112 64\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            # 输出 112-3+2+1 = 112\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            # 输出 112 112 128\n            nn.MaxPool2d(kernel_size=2, stride=2)\n            # 输出 56 56 128\n        )\n        self.conv_pool3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            # 输出 56-3+2+1=56\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            # 输出 56\n            nn.MaxPool2d(kernel_size=2, stride=2)\n            # 输出 28 28 256\n        )\n        self.conv_pool4 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            # 输出28 28 512\n            nn.MaxPool2d(kernel_size=2, stride=2)\n            # 输出14 14 512\n        )\n        self.conv_pool5 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            # 输出 14 14 512\n            nn.MaxPool2d(kernel_size=2, stride=2)\n            # 输出 7 7 512\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(7*7*512, 4096),\n            nn.Dropout(), #0.5概率神经元失活\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, 11)\n            # 使用交叉熵误差函数，最后一层不用softmax\n        )\n    def forward(self, x):\n        x = self.conv_pool1(x)\n        x = self.conv_pool2(x)\n        x = self.conv_pool3(x)\n        x = self.conv_pool4(x)\n        x = self.conv_pool5(x)\n        x = x.view(-1, 7*7*512)\n        x = self.fc(x)\n        return x\n\nmodel_vgg = my_VGG19().to(dvc)\nsummary(model_vgg, (3, 224, 224))","metadata":{"papermill":{"duration":1.09864,"end_time":"2023-11-05T12:19:00.974755","exception":false,"start_time":"2023-11-05T12:18:59.876115","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.687380Z","iopub.status.idle":"2023-11-07T06:55:23.687746Z","shell.execute_reply.started":"2023-11-07T06:55:23.687576Z","shell.execute_reply":"2023-11-07T06:55:23.687599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\nimport time\nfrom torch.optim.lr_scheduler import StepLR\n\nSHA_TZ = timezone(\n    timedelta(hours=8),\n    name='Asia/Shanghai',\n)\n\ndef get_cos(t):\n    return 0.000015 + 0.00001499*math.cos(2*math.pi*t/10)\n\n\ndef vgg_train_valid(model, train_set, valid_set):\n    writer = SummaryWriter('/kaggle/working/runs/vgg') # 开始记录\n    loss_func = nn.CrossEntropyLoss() #交叉熵损失\n    epochs = 100\n    good_num = 0\n    start_time = time.time()\n    for epoch in range(epochs):\n        lr = get_cos(epoch)\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr) #优化器以及学习率\n        if good_num >= 5:\n            print(f'run {epoch} epoch')\n            break\n        model.train()\n        sum_loss = 0\n        train_correct = 0\n        time_now = datetime.utcnow().astimezone(SHA_TZ)\n        print(f'[{epoch+1}/{epochs}]  time now: {time_now.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n        for i, data in enumerate(train_set, 0):\n            features, labels = data\n            data_len = len(data[0])\n            features, labels = features.to(dvc), labels.to(dvc)\n            preds = model(features)\n            model.zero_grad() #梯度清零\n            # 计算损失\n            loss = loss_func(preds, labels)\n            loss.backward() # 反向传播\n            optimizer.step()\n            sum_loss += loss.data\n            _, ans = torch.max(preds, 1) # 此时preds第0维度有5个数据，ans也是5*1的张量\n            train_correct += torch.sum(ans==labels.data) # ans5*1 ，这里输出的是5个里面预测准确的数量\n        train_ac = 100*train_correct/(len(train_set)*data_len) # 训练集准确率\n        train_loss = 100*sum_loss/(len(train_set)*data_len) # 训练集损失\n        print(f'Loss on train set: {train_loss:.3f} Accuracy on train set: {train_ac:.3f}%')\n        valid_ac = valid(model, valid_set) # 测试集准确率(有输出)\n        if valid_ac > 90 or train_ac > 99:\n            good_num += 1\n        elif valid_ac == 95:\n            good_num = 5\n        writer.add_scalar(\"Accuracy/train\", train_ac, epoch)\n        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n        writer.add_scalar(\"Accuracy/valid\", valid_ac, epoch)\n    end_time = time.time()\n    print(f'cost time {end_time - start_time} s')\n    writer.close() # 结束记录","metadata":{"papermill":{"duration":0.09125,"end_time":"2023-11-05T12:19:01.138896","exception":false,"start_time":"2023-11-05T12:19:01.047646","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.689721Z","iopub.status.idle":"2023-11-07T06:55:23.690051Z","shell.execute_reply.started":"2023-11-07T06:55:23.689888Z","shell.execute_reply":"2023-11-07T06:55:23.689903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_train_valid(model_vgg, train_set, valid_set)","metadata":{"papermill":{"duration":207.982294,"end_time":"2023-11-05T12:22:29.193860","exception":false,"start_time":"2023-11-05T12:19:01.211566","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.690974Z","iopub.status.idle":"2023-11-07T06:55:23.691298Z","shell.execute_reply.started":"2023-11-07T06:55:23.691136Z","shell.execute_reply":"2023-11-07T06:55:23.691151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model_vgg, '/kaggle/working/vggcos.pth')","metadata":{"papermill":{"duration":0.839271,"end_time":"2023-11-05T12:22:30.105813","exception":false,"start_time":"2023-11-05T12:22:29.266542","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.692981Z","iopub.status.idle":"2023-11-07T06:55:23.693367Z","shell.execute_reply.started":"2023-11-07T06:55:23.693185Z","shell.execute_reply":"2023-11-07T06:55:23.693203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 对测试集进行预测，保存结果到ans_vgg.csv中","metadata":{"papermill":{"duration":0.074798,"end_time":"2023-11-05T12:22:30.254698","exception":false,"start_time":"2023-11-05T12:22:30.179900","status":"completed"},"tags":[]}},{"cell_type":"code","source":"save_predict_csv(model_vgg, test_set, len(test_set), ['pred', 'filename'], '/kaggle/working/ans_vgg.csv', test_pic_names)","metadata":{"papermill":{"duration":721.790078,"end_time":"2023-11-05T12:34:32.118228","exception":false,"start_time":"2023-11-05T12:22:30.328150","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-07T06:55:23.694708Z","iopub.status.idle":"2023-11-07T06:55:23.695033Z","shell.execute_reply.started":"2023-11-07T06:55:23.694873Z","shell.execute_reply":"2023-11-07T06:55:23.694888Z"},"trusted":true},"execution_count":null,"outputs":[]}]}